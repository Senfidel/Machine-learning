#Librairies de base
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
#Librairies pour le machine learning
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split, learning_curve, cross_val_score, train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline,  make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import PolynomialFeatures
#Librairies pour le d√©ploiement
import streamlit as st
import joblib
import os
#Librairie de g√©ocodage
import pycountry





# Sp√©cifiez les chemins absolus pour chaque mod√®le
model_paths = {
'KNeighborsRegressor': "KNeighborsRegressor_pipeline.pkl",
    'Polynomial Regression': "Polynomial_Regression_pipeline.pkl",
    'ElasticNet': "ElasticNet_pipeline.pkl",
    'BaggingRegressor': "BaggingRegressor_pipeline.pkl",
    'RandomForestRegressor': "RandomForestRegressor_pipeline.pkl",
    'GradientBoostingRegressor': "GradientBoostingRegressor_pipeline.pkl",
    'AdaBoostRegressor': "AdaBoostRegressor_pipeline.pkl",
    'SVR': "SVR_pipeline.pkl"
}

# Chargement des mod√®les
models = {name: joblib.load(path) for name, path in model_paths.items()}

# Chargement des donn√©es
df = pd.read_csv(
    "salaries_cleaned.csv")

y = np.log1p(df['salary_in_usd'])
X = df.drop(["salary_in_usd", 'salary'], axis=1)

# Division des donn√©es en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Configuration de l'application Streamlit
st.set_page_config(page_title='Vitrine des Mod√®les', layout='wide', initial_sidebar_state='expanded')

# Barre lat√©rale pour la navigation entre les pages
st.sidebar.title("Navigation")
st.image( "th.jpeg")
pages = ["Contexte du Projet", "Vitrine des Mod√®les", "Pr√©dictions avec SVR"]
page = st.sidebar.selectbox("S√©lectionnez une Page:", pages)

if page == "Contexte du Projet":
    st.title("Contexte du Projet")
    st.markdown("""
    #### Objectif du projet

    Le but de ce projet est de produire une application √† partir d'un mod√®le de machine learning qui pr√©dit le salaire des data scientists en fonction de leurs caract√©ristiques. Il s'agit d'un probl√®me de r√©gression.

    #### Les √©tapes du projet

    1. **Collecte et r√©cup√©ration des donn√©es**

        Selon [**CHALONS, G., 2022**](https://kaizen-solutions.net/kaizen-insights/articles-et-conseils-de-nos-experts/cycle-de-vie-projet-machine-learning-8-etapes/), "Les projets de Machine Learning sont des processus longs, du fait qu'ils n√©cessitent notamment de collecter une grande quantit√© de donn√©es afin d'apporter une r√©ponse robuste, fiable et stable." Cependant, nous n'avons pas eu √† effectuer cette t√¢che, car nous utilisons des donn√©es propres disponibles sur Kaggle. Vous pouvez acc√©der au dataset et √† sa description via ce [**lien**](https://www.kaggle.com/datasets/abhinavshaw09/data-science-job-salaries-2024).


    2. **Exploration et Visualisation des donn√©es**

        Cette √©tape, ainsi que la suivante, nous a permis de mieux comprendre l'environnement √©tudi√©, d'√©viter certains biais et de fournir des donn√©es de qualit√© aux algorithmes de machine learning choisis. Elle m'a permis de bien visualiser la distribution des salaires, d'identifier les doublons et les asym√©tries de la distribution des salaires. Elle m'a aussi montr√© qu'il n'y avait pas de valeurs manquantes dans le jeu de donn√©es.

    3. **Pr√©paration des donn√©es**

        Comme dans tout projet informatique, la qualit√© des donn√©es entrantes impacte fortement les r√©sultats : "Garbage In, Garbage Out". Nous avons supprim√© les doublons et corrig√© les asym√©tries identifi√©es ([voir le notebook ](https://github.com/Senfidel/Machine-learning/blob/main/Script.ipynb)) durant l'√©tape pr√©c√©dente. Nous avons √©galement enrichi les donn√©es en convertissant les codes des pays en noms complets gr√¢ce √† la librairie pycountry et recod√© plusieurs autres variables pour am√©liorer leur lisibilit√© par l'utilisateur.

    4. **Choix et impl√©mentation des mod√®les**

        Nous avons test√© plusieurs algorithmes de r√©gression : **k-NN Regression, Polynomial Regression, ElasticNet, BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor** et **SVR**, en comparant leurs capacit√©s de g√©n√©ralisation. Notre choix de ces mod√®les est en partie motiv√© par notre volont√© de mise en pratique et de compr√©hension d'un grand nombre d'algorithmes de machine learning.

    5. **Entra√Ænement, √©valuation et validation des mod√®les**

        Afin d'√©viter d'introduire des biais statistiques menant g√©n√©ralement √† un sous-apprentissage ou √† un surapprentissage des mod√®les, nous avons divis√© le jeu de donn√©es en deux parties. La premi√®re partie (80 % des donn√©es) a servi √† entra√Æner les mod√®les, tandis que la deuxi√®me partie (20 % des donn√©es) a √©t√© utilis√©e pour les tester. Nous avons effectu√© cette s√©paration de mani√®re al√©atoire et reproductible. Pour optimiser les hyperparam√®tres, nous avons choisi des grilles de recherche plus ou moins simples en fonction du temps d'apprentissage des algorithmes utilis√©s, afin d'optimiser le temps d'apprentissage. En effet, les algorithmes √† entra√Æner √©taient relativement nombreux et cette phase du projet est tr√®s gourmande en ressources de calcul (CPU, GPU) et en temps. Nous avons d√ª interrompre l'optimisation des hyperparam√®tres lors du premier essai car l'ordinateur avait tourn√© pendant plus de 24 heures sans √©puiser les combinaisons possibles des grilles que nous lui avions soumises. Apr√®s avoir trouv√© les grilles optimales, nous avons s√©lectionn√© les combinaisons d'hyperparam√®tres qui minimisaient le plus le MSE (Mean Squared Error) de chaque algorithme. Apr√®s l'optimisation des hyperparam√®tres, nous avons compar√© la capacit√© des algorithmes √† pr√©dire les donn√©es test et s√©lectionn√© celui qui avait le MSE le plus faible. C'est ce mod√®le (le mod√®le SVR) que nous avons d√©ploy√© en production.

    6. **D√©ploiement du mod√®le**

        Nous avons cr√©√© une application Streamlit dans laquelle nous avons encapsul√© les diff√©rents mod√®les. Dans la premi√®re page de l'application, nous pr√©sentons le contexte du projet (description sommaire et quelques visualisations). Dans la deuxi√®me page, nous pr√©sentons des pr√©dictions des algorithmes sur un √©chantillon des donn√©es test. La derni√®re page est r√©serv√©e √† l'utilisation du mod√®le SVR pour la pr√©diction des salaires.
    """)


    st.write("### Exploration des donn√©es")
    st.dataframe(df.head())
    if st.checkbox("Dimensions du dataframe : "):
        st.write(df.shape)

    df['log_salary'] = np.log1p(df['salary_in_usd'])
    fig1 = px.box(df, y='salary_in_usd', template="seaborn", title="Salary Distribution")
    st.plotly_chart(fig1)

    fig2 = px.scatter(df, x='job_title', y='log_salary', template="seaborn", title="Job Title vs. Log Salary")
    st.plotly_chart(fig2)

    z3 = df['job_title'].value_counts().head(10)
    fig3 = px.bar(z3, x=z3.index, y=z3.values, color=z3.index, text=z3.values,
                  labels={'index': 'Job Title', 'y': 'Count', 'text': 'Count'}, template='seaborn',
                  title='<b>Top 10 Popular Roles in Data Science</b>')
    st.plotly_chart(fig3)

    top_paid_roles = df.groupby('job_title', as_index=False)['log_salary'].max().sort_values(by='log_salary',
                                                                                             ascending=False).head(10)
    fig4= px.bar(top_paid_roles, x='job_title', y='log_salary', color='job_title',
                   labels={'job_title': 'Job Title', 'log_salary': 'Log Salary'}, template='ggplot2',
                   text='log_salary', title='<b>Top 10 Highest Paid Roles in Data Science</b>')
    st.plotly_chart(fig4)

    avg_paid_roles = df.groupby('job_title', as_index=False)['log_salary'].mean().sort_values(by='log_salary',
                                                                                              ascending=False).head(10)
    avg_paid_roles['log_salary'] = round(avg_paid_roles['log_salary'], 2)
    fig5 = px.bar(avg_paid_roles, x='job_title', y='log_salary', color='job_title',
                   labels={'job_title': 'Job Title', 'log_salary': 'Avg Salary in USD'}, text='log_salary',
                   template='seaborn', title='<b>Top 10 Roles in Data Science based on Average Pay</b>')
    fig5.update_traces(textfont_size=8)
    st.plotly_chart(fig5)

    fig6 = px.histogram(df, x='log_salary', marginal='rug', template='seaborn',
                         labels={'log_salary': 'Salary in USD'}, title='<b>Salary Distribution</b>')
    st.plotly_chart(fig6)

    fig7 = px.violin(df, x='work_year', y='log_salary', color='work_year',
                      labels={'work_year': 'Year', 'log_salary': 'Log Salary'}, template='seaborn',
                      title='<b>Data Science Salaries by Year</b>')
    st.plotly_chart(fig7)

    fig8 = px.box(df, x='experience_level', y='log_salary', color='experience_level', template='ggplot2',
                   labels={'experience_level': 'Experience Level', 'log_salary': 'Log Salary'},
                   title='<b>Data Science Salaries by Experience</b>')
    st.plotly_chart(fig8)

    fig9 = px.box(df, x='company_size', y='log_salary', color='company_size', template='ggplot2',
                   labels={'company_size': 'Company Size', 'log_salary': 'Log Salary'},
                   title='<b>Data Science Salaries by Company Size</b>')
    st.plotly_chart(fig9)



if page == "Vitrine des Mod√®les":
    st.title("üèÜ Vitrine des Mod√®les")

    # Sidebar pour la s√©lection du mod√®le
    st.sidebar.title("S√©lectionner un Mod√®le")
    selected_model = st.sidebar.selectbox("Choisissez un mod√®le √† explorer", list(models.keys()))

    # Affichage des d√©tails du mod√®le
    st.header(f"Mod√®le : {selected_model}")

    # Affichage des d√©tails du mod√®le
    model = models[selected_model]
    y_pred = model.predict(X_test)
    test_score = mean_squared_error(y_test, y_pred)

    st.write(f"### Score de Test (MSE) : {test_score}")

    #st.write("### Param√®tres du Mod√®le :")
    #st.json(model.get_params())

    # Affichage des pr√©dictions pour un √©chantillon de donn√©es de test
    st.write("### Pr√©dictions sur un √âchantillon des Donn√©es de Test :")
    sample_data = X_test.head(10)
    sample_predictions = model.predict(sample_data)

    st.write(pd.DataFrame({
        'Salaire R√©el (log)': y_test.head(10).values,
        'Salaire Pr√©dit (log)': sample_predictions
    }))

    # Comparaison des mod√®les
    st.sidebar.title("Comparer les Mod√®les")
    if st.sidebar.checkbox("Comparer tous les mod√®les"):
        st.subheader("Comparaison des Mod√®les")
        comparison_data = []

        for name, mdl in models.items():
            y_pred = mdl.predict(X_test)
            score = mean_squared_error(y_test, y_pred)
            comparison_data.append((name, score))

        comparison_df = pd.DataFrame(comparison_data, columns=['Mod√®le', 'MSE']).sort_values(by='MSE')
        st.write(comparison_df)

    # Stylisation de l'application
    st.markdown("""
        <style>
        .main {
            background-color: #f0f2f6;
        }
        .stButton>button {
            background-color: #4CAF50;
            color: white;
        }
        .stSidebar .stSelectbox>div>div {
            background-color: #4CAF50;
            color: white;
        }
        </style>
        """, unsafe_allow_html=True)

    # Ajout d'un footer
    st.markdown("""
        <style>
        footer {
            visibility: hidden;
        }
        footer:after {
            content:'D√©velopp√© par Votre Nom';
            visibility: visible;
            display: block;
            position: relative;
            padding: 5px;
            top: 2px.
        }
        </style>
        """, unsafe_allow_html=True)

elif page == "Pr√©dictions avec SVR":
    st.title("üîç Pr√©dictions de Salaire avec SVR")
    # Section pour la saisie des donn√©es utilisateur
    st.markdown("<h3 style='font-size:20px;'>Saisir les Caract√©ristiques de l'Usager :</h3>", unsafe_allow_html=True)
    with st.form("prediction_form"):
        work_year = st.number_input("**Ann√©e de Travail (2020-2024)**", min_value=2020, max_value=2024, step=1)
        salary_currency = st.selectbox("**Devise du Salaire (USD, EUR, GBP, etc.)**", df['salary_currency'].unique())
        experience_level = st.selectbox("**Niveau d'Exp√©rience (D√©butant, Interm√©diaire, Cadre, Senior)**",
                                        ['D√©butant', 'Interm√©diaire', 'Cadre', 'Senior'])
        job_title = st.selectbox("**Titre du Poste**", df['job_title'].unique())
        employee_residence = st.selectbox("**R√©sidence de l'Usager**", df['employee_residence'].unique())
        remote_ratio = st.number_input("**Ratio de T√©l√©travail (0-100)**", min_value=0, max_value=100, step=1)
        company_location = st.selectbox("**Localisation de l'Entreprise**", df['company_location'].unique())
        company_size = st.selectbox("**Taille de l'Entreprise (S, M, L)**", df['company_size'].unique())
        employment_type = st.selectbox("**Type d'emploi**", df['employment_type'].unique())

        submitted = st.form_submit_button("**Pr√©dire**")

    if submitted:
            input_data = pd.DataFrame({
                'work_year': [work_year],
                'salary_currency': [salary_currency],
                'experience_level': [experience_level],
                'job_title': [job_title],
                'employee_residence': [employee_residence],
                'remote_ratio': [remote_ratio],
                'company_location': [company_location],
                'company_size': [company_size],
                'employment_type': [employment_type]
            })
            st.write("### Donn√©es Saisies :")
            st.write(input_data)

            # Make prediction using the SVR model
            prediction = models['SVR'].predict(input_data)
            prediction_usd = np.expm1(prediction)  # Convert back from log scale
            prediction_eur = prediction_usd * 0.85  # Convert to EUR using exchange rate 1 USD = 0.85 EUR

            st.write(f"### Salaire Pr√©dit en Dollars : $ {prediction_usd[0]:,.2f}")
            st.write(f"### Salaire Pr√©dit en Euros : ‚Ç¨ {prediction_eur[0]:,.2f}")

    # Apply some styling to the app
    st.markdown("""
        <style>
        .main {
            background-color: #f0f2f6;
        }
        .stButton>button {
            background-color: #4CAF50;
            color: white;
        }
        .stSidebar .stSelectbox>div>div {
            background-color: #4CAF50;
            color: white;
        }
        </style>
        """, unsafe_allow_html=True)

    # Adding a footer
    st.markdown("""
        <style>
        footer {
            visibility: hidden;
        }
        footer:after {
            content:'D√©velopp√© par Votre Nom';
            visibility: visible;
            display: block;
            position: relative;
            padding: 5px;
            top: 2px.
        }
        </style>
        """, unsafe_allow_html=True)
